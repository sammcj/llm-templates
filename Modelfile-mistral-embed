
#  ollama create linq-embed-mistral:q6_k -f modelfiles/Modelfile-mistral-embed

#  https://huggingface.co/Linq-AI-Research/Linq-Embed-Mistral
FROM ../linq-embed-mistral.gguf


### Tuning ##
PARAMETER num_ctx 4096

#  {
#    "_name_or_path": "intfloat/e5-mistral-7b-instruct",
#    "architectures": [
#      "MistralModel"
#    ],
#    "attention_dropout": 0.0,
#    "bos_token_id": 1,
#    "eos_token_id": 2,
#    "hidden_act": "silu",
#    "hidden_size": 4096,
#    "initializer_range": 0.02,
#    "intermediate_size": 14336,
#    "max_position_embeddings": 32768,
#    "model_type": "mistral",
#    "num_attention_heads": 32,
#    "num_hidden_layers": 32,
#    "num_key_value_heads": 8,
#    "pad_token_id": 2,
#    "rms_norm_eps": 1e-05,
#    "rope_theta": 10000.0,
#    "sliding_window": 4096,
#    "tie_word_embeddings": false,
#    "torch_dtype": "float16",
#    "transformers_version": "4.39.0",
#    "use_cache": false,
#    "vocab_size": 32000
#  }
