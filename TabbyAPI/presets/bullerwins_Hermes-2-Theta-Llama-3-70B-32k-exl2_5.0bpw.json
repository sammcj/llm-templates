{
    "name": "bullerwins_Hermes-2-Theta-Llama-3-70B-32k-exl2_5.0bpw",
    "max_seq_len": 8192,
    "override_base_seq_len": null,
    "cache_size": 8192,
    "gpu_split_auto": true,
    "gpu_split": "",
    "rope_scale": null,
    "rope_alpha": null,
    "cache_mode": "Q4",
    "prompt_template": "chatml",
    "num_experts_per_token": null,
    "draft_model_name": "bartowski_Hermes-2-Theta-Llama-3-8B-exl2",
    "draft_rope_scale": null,
    "draft_rope_alpha": null,
    "draft_cache_mode": "Q4",
    "fasttensors": true,
    "autosplit_reserve": "",
    "chunk_size": null
}